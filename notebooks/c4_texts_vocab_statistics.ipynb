{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DRi6kHk8ECaT"
   },
   "source": [
    "# Configuración inicial\n",
    "\n",
    "* En este notebook vamos a descargar el dataset `book` que contiene muchos libros en ingles en formato de texto tokenizado, de los cuales vamos a hacer procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DLeLwV_ND0Pq"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('book')\n",
    "from nltk.book import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEFQ7N_OF3W_"
   },
   "source": [
    "# Analizando un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# escogemos text1 que es el famoso libro Moby Dick\n",
    "text1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tm95nIKgJZ0F"
   },
   "source": [
    "## Medida de riqueza lexica en un texto: \n",
    "$$ R_l = \\frac{\\text{total de palabras únicas}}{\\text{total de palabras}} = \\frac{\\text{longitud del vocabulario}}{\\text{longitud del texto}}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Forthwith',\n",
       " 'unaided',\n",
       " 'inactive',\n",
       " 'surprise',\n",
       " 'desk',\n",
       " 'interpenetrate',\n",
       " 'dearly',\n",
       " 'lubber',\n",
       " 'ditchers',\n",
       " 'ladies',\n",
       " 'spirally',\n",
       " 'pyres',\n",
       " 'buries',\n",
       " 'Lais',\n",
       " 'immensely',\n",
       " 'ranks',\n",
       " 'consign',\n",
       " 'Northern',\n",
       " 'stately',\n",
       " 'employed',\n",
       " 'Blanket',\n",
       " 'contingent',\n",
       " 'green',\n",
       " 'onward',\n",
       " 'wasps',\n",
       " 'respectively',\n",
       " 'soladoes',\n",
       " 'placed',\n",
       " 'corkscrew',\n",
       " 'twiske',\n",
       " 'pox',\n",
       " 'murderer',\n",
       " 'brigs',\n",
       " 'elder',\n",
       " 'Usually',\n",
       " 'philosophical',\n",
       " 'trencher',\n",
       " '99',\n",
       " 'breadfruit',\n",
       " 'jobs',\n",
       " 'czar',\n",
       " 'conveniences',\n",
       " 'justify',\n",
       " 'encamped',\n",
       " 'analogies',\n",
       " 'caressed',\n",
       " 'centralization',\n",
       " 'handling',\n",
       " 'WHALING',\n",
       " 'livingly']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primero realizamos la construcción de un vocabulario (identificamos las palabras unicas que hay en el libro)\n",
    "# https://docs.python.org/2/library/sets.html\n",
    "\n",
    "# el voculario es la lista de palabras unicas de un lenguaje\n",
    "\n",
    "vocabulario = list(set(text1))\n",
    "vocabulario[1000:1050]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crew',\n",
       " 'Crish',\n",
       " 'Crockett',\n",
       " 'Cross',\n",
       " 'Crossed',\n",
       " 'Crossing',\n",
       " 'Crotch',\n",
       " 'Crowding',\n",
       " 'Crown',\n",
       " 'Crozetts',\n",
       " 'Cruelty',\n",
       " 'Cruising',\n",
       " 'Cruppered',\n",
       " 'Crusaders',\n",
       " 'Crushed',\n",
       " 'Crying',\n",
       " 'Cuba',\n",
       " 'Curious',\n",
       " 'Curse',\n",
       " 'Cursed',\n",
       " 'Curses',\n",
       " 'Cussed',\n",
       " 'Customs',\n",
       " 'Cut',\n",
       " 'Cutter',\n",
       " 'Cutting',\n",
       " 'Cuvier',\n",
       " 'Cyclades',\n",
       " 'Czar',\n",
       " 'D',\n",
       " 'DAGGOO',\n",
       " 'DAM',\n",
       " 'DANCE',\n",
       " 'DANCING',\n",
       " 'DANIEL',\n",
       " 'DANISH',\n",
       " 'DARKENS',\n",
       " 'DARWIN',\n",
       " 'DAVENANT',\n",
       " 'DEAD',\n",
       " 'DEATH',\n",
       " 'DEBELL',\n",
       " 'DECK',\n",
       " 'DEL',\n",
       " 'DESTROYED',\n",
       " 'DEVIL',\n",
       " 'DICTIONARY',\n",
       " 'DID',\n",
       " 'DIGNITY',\n",
       " 'DISCOVERS']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulario = sorted(set(text1))\n",
    "vocabulario[1000:1050]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07406285585022564"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl = len(vocabulario) / len(text1)\n",
    "rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19317"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_richness(text):\n",
    "    return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07406285585022564"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_richness(text1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04826383002768831"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_richness(text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_percentage(word, text):\n",
    "    return 100 * text.count(word) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018786974875296663"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_percentage('monster', text1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.260736372733581"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_percentage('the', text1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count('monster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13721"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count('the')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('datascience_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee8799877915b2128d18d4b1666f364b6042f264ec4835ead054518ba3b9d1ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
